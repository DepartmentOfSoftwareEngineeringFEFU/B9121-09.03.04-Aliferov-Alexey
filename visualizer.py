from tkinter import messagebox
import numpy as np
import pypianoroll
import mido
import pygame
import pygame.midi
import time
import sounddevice as sd
import soundfile as sf
import threading
import queue
from pathlib import Path
from const import (MIN_NOTE, MAX_NOTE, WHITE_KEY_WIDTH, BLACK_KEY_WIDTH, 
                   WHITE_KEY_HEIGHT, BLACK_KEY_HEIGHT, KEY_HEIGHT, SCREEN_WIDTH, 
                   SCREEN_HEIGHT, LEAD_TIME, is_white_key, is_black_key)
from reference_generator import ReferenceGenerator
from performance_evaluator import PerformanceEvaluator

class AudioRecorder:
    """–ö–ª–∞—Å—Å –¥–ª—è –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ –≤–æ –≤—Ä–µ–º—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏."""
    
    def __init__(self, device_name=None, sample_rate=44100):
        self.device_name = device_name
        self.sample_rate = sample_rate
        self.audio_queue = queue.Queue()
        self.recording = False
        self.recorded_data = []
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º device_id –∏–∑ –∏–º–µ–Ω–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        self.device_id = None
        if device_name:
            devices = sd.query_devices()
            for idx, dev in enumerate(devices):
                if f"{dev['name']} (#{idx})" == device_name:
                    self.device_id = idx
                    break
    
    def _audio_callback(self, indata, frames, time, status):
        """Callback-—Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ."""
        if status:
            print(f"Audio callback status: {status}")
        if self.recording:
            self.audio_queue.put(indata.copy())
    
    def start_recording(self):
        """–ù–∞—á–∏–Ω–∞–µ—Ç –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ."""
        self.recording = True
        self.recorded_data = []
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö
        self.processing_thread = threading.Thread(target=self._process_audio_queue)
        self.processing_thread.start()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å—å
        self.stream = sd.InputStream(
            device=self.device_id,
            samplerate=self.sample_rate,
            channels=1,
            callback=self._audio_callback
        )
        self.stream.start()
    
    def _process_audio_queue(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—á–µ—Ä–µ–¥—å –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö."""
        while self.recording or not self.audio_queue.empty():
            try:
                data = self.audio_queue.get(timeout=0.1)
                self.recorded_data.append(data.flatten())
            except queue.Empty:
                continue
    
    def stop_recording(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–∞–ø–∏—Å—å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."""
        self.recording = False
        
        if hasattr(self, 'stream'):
            self.stream.stop()
            self.stream.close()
        
        if hasattr(self, 'processing_thread'):
            self.processing_thread.join()
        
        if self.recorded_data:
            return np.concatenate(self.recorded_data)
        else:
            return np.array([])

def parse_midi(path_to_midi):
    """
    –ß–∏—Ç–∞–µ—Ç MIDI‚Äë—Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç NumPy‚Äë–º–∞—Å—Å–∏–≤ —Å–æ–±—ã—Ç–∏–π –¥–ª—è –ø–∞–¥–∞—é—â–µ–≥–æ –ø–∏–∞–Ω–æ—Ä–æ–ª–ª–∞.
    """
    multitrack = pypianoroll.read(path_to_midi)
    resolution = multitrack.resolution

    merged = multitrack.blend(mode='max').astype(np.int16)

    mid = mido.MidiFile(path_to_midi)
    tempo = 500_000
    for track in mid.tracks:
        for msg in track:
            if msg.type == 'set_tempo':
                tempo = msg.tempo
                break
        if tempo != 500_000:
            break

    sec_per_tick = (tempo / 1_000_000) / resolution

    T, P = merged.shape
    prev = np.zeros((P,), dtype=np.int16)
    ongoing = {}
    events_list = []

    for t in range(T):
        for p in range(P):
            vel = int(merged[t, p])
            if vel > 0 and prev[p] == 0:
                ongoing[p] = {'t_on_tick': t, 'vel': vel}
            elif vel == 0 and prev[p] > 0:
                if p in ongoing:
                    t0 = ongoing[p]['t_on_tick']
                    v0 = ongoing[p]['vel']
                    t_on_sec = t0 * sec_per_tick
                    t_off_sec = t * sec_per_tick
                    events_list.append((p, t_on_sec, t_off_sec, v0))
                    del ongoing[p]
        prev[:] = merged[t, :]

    for p, info in ongoing.items():
        t0 = info['t_on_tick']
        v0 = info['vel']
        t_on_sec = t0 * sec_per_tick
        t_off_sec = T * sec_per_tick
        events_list.append((p, t_on_sec, t_off_sec, v0))

    events_list.sort(key=lambda x: x[1])

    dtype = np.dtype([
        ('pitch',    np.int16),
        ('t_on',     np.float64),
        ('t_off',    np.float64),
        ('velocity', np.int16)
    ])
    events_array = np.array(events_list, dtype=dtype)
    return events_array

def pitch_to_key_position(pitch):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–∑–∏—Ü–∏—é –∏ —Ä–∞–∑–º–µ—Ä—ã –∫–ª–∞–≤–∏—à–∏ –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–π MIDI-–Ω–æ—Ç—ã."""
    if pitch < MIN_NOTE or pitch > MAX_NOTE:
        return None
    
    if is_white_key(pitch):
        white_keys_before = 0
        for note in range(MIN_NOTE, pitch):
            if is_white_key(note):
                white_keys_before += 1
        
        x = white_keys_before * WHITE_KEY_WIDTH
        return {
            'x': x,
            'width': WHITE_KEY_WIDTH,
            'height': WHITE_KEY_HEIGHT,
            'is_black': False
        }
    else:
        left_white_pitch = pitch - 1
        while left_white_pitch >= MIN_NOTE and is_black_key(left_white_pitch):
            left_white_pitch -= 1
        
        if left_white_pitch < MIN_NOTE:
            return None
            
        white_keys_before_left_white = 0
        for note in range(MIN_NOTE, left_white_pitch):
            if is_white_key(note):
                white_keys_before_left_white += 1
        
        left_white_x = white_keys_before_left_white * WHITE_KEY_WIDTH
        x = left_white_x + WHITE_KEY_WIDTH - BLACK_KEY_WIDTH // 2
        return {
            'x': x,
            'width': BLACK_KEY_WIDTH,
            'height': BLACK_KEY_HEIGHT,
            'is_black': True
        }

def pitch_to_color(pitch):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ü–≤–µ—Ç –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–π MIDI-–Ω–æ—Ç—ã."""
    import colorsys
    
    if pitch < MIN_NOTE or pitch > MAX_NOTE:
        return (128, 128, 128)
    
    note = pitch % 12
    hue = note / 12.0
    saturation = 0.9
    value = 0.95
    
    r, g, b = colorsys.hsv_to_rgb(hue, saturation, value)
    return (int(r * 255), int(g * 255), int(b * 255))

class NoteRect:
    """–û–ø–∏—Å—ã–≤–∞–µ—Ç –Ω–æ—Ç—É –≤ –ø–∏–∞–Ω–æ—Ä–æ–ª–ª–µ."""
    def __init__(self, pitch, t_on, t_off, velocity, pixels_per_second):
        self.pitch = pitch
        self.t_on = t_on
        self.t_off = t_off
        self.velocity = velocity
        self.pixels_per_second = pixels_per_second

        key_pos = pitch_to_key_position(pitch)
        if key_pos:
            self.x = key_pos['x']
            self.width = key_pos['width']
            self.is_black = key_pos['is_black']
        else:
            self.x = None
            self.width = None
            self.is_black = False
        
        dur = t_off - t_on
        self.height = max(int(dur * pixels_per_second), 8)
        self.color = pitch_to_color(pitch)

    def draw(self, surface, y_offset, key_top_y, current_time):
        """–†–∏—Å—É–µ—Ç –Ω–æ—Ç—É —Å —É—á–µ—Ç–æ–º —Ç–µ–∫—É—â–µ–≥–æ —Å–º–µ—â–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Å–ª–æ—è."""
        if self.x is None:
            return
            
        note_y_in_layer = -self.height
        note_y_on_screen = note_y_in_layer + y_offset
        
        if (note_y_on_screen < SCREEN_HEIGHT and 
            note_y_on_screen + self.height > 0):
            
            rect = pygame.Rect(self.x, int(note_y_on_screen), self.width, self.height)
            pygame.draw.rect(surface, self.color, rect)

def draw_keyboard(screen):
    """–†–∏—Å—É–µ—Ç –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –ø–∏–∞–Ω–∏–Ω–æ."""
    key_top_y = SCREEN_HEIGHT - KEY_HEIGHT
    
    for note in range(MIN_NOTE, MAX_NOTE + 1):
        if is_white_key(note):
            key_pos = pitch_to_key_position(note)
            if key_pos:
                rect = pygame.Rect(key_pos['x'], key_top_y, key_pos['width'], key_pos['height'])
                pygame.draw.rect(screen, (255, 255, 255), rect)
                pygame.draw.rect(screen, (50, 50, 50), rect, 1)
    
    for note in range(MIN_NOTE, MAX_NOTE + 1):
        if is_black_key(note):
            key_pos = pitch_to_key_position(note)
            if key_pos:
                rect = pygame.Rect(key_pos['x'], key_top_y, key_pos['width'], key_pos['height'])
                pygame.draw.rect(screen, (30, 30, 30), rect)
                pygame.draw.rect(screen, (100, 100, 100), rect, 1)

def highlight_active_keys(screen, active_keys):
    """–ü–æ–¥—Å–≤–µ—á–∏–≤–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–µ –∫–ª–∞–≤–∏—à–∏ –ø–æ–≤–µ—Ä—Ö –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã."""
    key_top_y = SCREEN_HEIGHT - KEY_HEIGHT
    
    for pitch, color in active_keys:
        key_pos = pitch_to_key_position(pitch)
        if key_pos:
            rect = pygame.Rect(key_pos['x'], key_top_y, key_pos['width'], key_pos['height'])
            pygame.draw.rect(screen, color, rect, 3)

def extract_device_id(device_name):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç ID —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –∏–∑ —Å—Ç—Ä–æ–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∞ '–ò–º—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (#ID)'."""
    if not device_name:
        return None
    
    import re
    match = re.search(r'#(\d+)\)$', device_name)
    if match:
        return int(match.group(1))
    return None

def run_visualization(midi_path, enable_sound=False, device_name=None):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Å –∑–∞–ø–∏—Å—å—é –∑–≤—É–∫–∞ –∏ –æ—Ü–µ–Ω–∫–æ–π –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è."""
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–æ–±—ã—Ç–∏—è –∏–∑ MIDI
    events = parse_midi(midi_path)
    if len(events) == 0:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ note_on/note_off –≤ MIDI.")
        return

    # –ù–∞—Ö–æ–¥–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã
    earliest_t_on = min(ev['t_on'] for ev in events)
    last_t_off = max(ev['t_off'] for ev in events)

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    lead_time = LEAD_TIME
    key_top_y = SCREEN_HEIGHT - KEY_HEIGHT
    travel_distance = key_top_y + 50
    pixels_per_second = travel_distance / lead_time

    # –°–æ–∑–¥–∞—ë–º —Å–ø–∏—Å–æ–∫ NoteRect
    note_rects = []
    for ev in events:
        if ev['pitch'] < MIN_NOTE or ev['pitch'] > MAX_NOTE:
            continue
        nr = NoteRect(
            pitch=ev['pitch'],
            t_on=ev['t_on'],
            t_off=ev['t_off'],
            velocity=ev['velocity'],
            pixels_per_second=pixels_per_second
        )
        note_rects.append(nr)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Pygame
    pygame.init()
    screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))
    pygame.display.set_caption("–ü–∏–∞–Ω–æ—Ä–æ–ª–ª-–∞–Ω–∏–º–∞—Ü–∏—è")
    clock = pygame.time.Clock()
    FPS = 60

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MIDI —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä–∞
    midi_out = None
    if enable_sound:
        pygame.midi.init()
        try:
            if pygame.midi.get_count() > 0:
                midi_out = pygame.midi.Output(pygame.midi.get_default_output_id())
            else:
                print("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö MIDI-—É—Å—Ç—Ä–æ–π—Å—Ç–≤ –¥–ª—è –≤—ã–≤–æ–¥–∞.")
        except Exception as e:
            print("–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ MIDI:", e)
            midi_out = None

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø–∏—Å–∏ –∑–≤—É–∫–∞
    recorder = None
    if device_name:
        try:
            recorder = AudioRecorder(device_name)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–∞–ø–∏—Å–∏ –∑–≤—É–∫–∞: {e}")
            recorder = None

    active_notes = set()
    midi_channel = 0

    # –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≥—Ä–∞–º–º—ã
    program_start_time = time.time()
    visualization_start_time = earliest_t_on - lead_time
    
    # –§–ª–∞–≥ –Ω–∞—á–∞–ª–∞ –∑–∞–ø–∏—Å–∏
    recording_started = False

    running = True
    while running:
        current_time = (time.time() - program_start_time) + visualization_start_time

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏–π
        for event in pygame.event.get():
            if event.type == pygame.QUIT:
                running = False

        # –û—á–∏—Å—Ç–∫–∞ —ç–∫—Ä–∞–Ω–∞
        screen.fill((30, 30, 30))

        # –í—ã—á–∏—Å–ª—è–µ–º —Å–º–µ—â–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Å–ª–æ—è
        elapsed_time = current_time - visualization_start_time
        active_keys = []

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å—å –≤ –º–æ–º–µ–Ω—Ç –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–≤–æ–π –Ω–æ—Ç—ã
        if not recording_started and recorder and current_time >= earliest_t_on:
            recorder.start_recording()
            recording_started = True
            print("–ù–∞—á–∞—Ç–∞ –∑–∞–ø–∏—Å—å –∑–≤—É–∫–∞")

        # MIDI: —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–≤—É—á–∞–Ω–∏–µ–º –Ω–æ—Ç
        notes_to_remove = set()
        for pitch in active_notes:
            still_active = any(
                nr.pitch == pitch and nr.t_on <= current_time <= nr.t_off
                for nr in note_rects
            )
            if not still_active and midi_out:
                try:
                    midi_out.note_off(int(pitch), 0)
                except TypeError:
                    midi_out.note_off(int(pitch), 0)
                notes_to_remove.add(pitch)
        active_notes -= notes_to_remove

        if elapsed_time >= 0:
            for nr in note_rects:
                time_until_touch = nr.t_on - current_time
                y_offset = -lead_time * pixels_per_second + (lead_time - time_until_touch) * pixels_per_second + key_top_y
                if time_until_touch <= lead_time and time_until_touch >= -2.0:
                    nr.draw(screen, y_offset, key_top_y, current_time)
                if nr.t_on <= current_time <= nr.t_off:
                    active_keys.append((nr.pitch, nr.color))
                    if midi_out and nr.pitch not in active_notes:
                        try:
                            midi_out.note_on(int(nr.pitch), int(max(1, min(nr.velocity, 127))), midi_channel)
                        except TypeError:
                            midi_out.note_on(int(nr.pitch), int(max(1, min(nr.velocity, 127))))
                        active_notes.add(nr.pitch)

        # –†–∏—Å—É–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –∏ –ø–æ–¥—Å–≤–µ—Ç–∫—É
        draw_keyboard(screen)
        highlight_active_keys(screen, active_keys)

        # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ, –µ—Å–ª–∏ –ø—Ä–æ—à–ª–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –Ω–æ—Ç—ã
        if current_time > last_t_off:
            running = False

        pygame.display.flip()
        clock.tick(FPS)

    # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ: –≤—ã–∫–ª—é—á–∞–µ–º –≤—Å–µ –Ω–æ—Ç—ã –∏ –∑–∞–∫—Ä—ã–≤–∞–µ–º MIDI
    if midi_out:
        for pitch in active_notes:
            try:
                midi_out.note_off(int(pitch), 0)
            except TypeError:
                midi_out.note_off(int(pitch), 0)
        midi_out.close()
        
    if enable_sound:
        pygame.midi.quit()

    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å –∏ –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    recorded_audio = None
    if recorder and recording_started:
        recorded_audio = recorder.stop_recording()
        print("–ó–∞–ø–∏—Å—å –∑–≤—É–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")

    pygame.quit()

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø–∏—Å–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ –∏ –æ—Ü–µ–Ω–∫–∞ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
    if recorded_audio is not None and len(recorded_audio) > 0:
        try:
            # –°–æ–∑–¥–∞—ë–º –≤—ã–¥–µ–ª–µ–Ω–Ω—ã–µ –ø–∞–ø–∫–∏, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
            recording_dir = Path("recorded_audio")
            recording_dir.mkdir(exist_ok=True)
            reference_dir = Path("reference_audio")
            reference_dir.mkdir(exist_ok=True)

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø–∏—Å–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ
            max_ampl = np.max(np.abs(recorded_audio))
            if max_ampl > 0.95:
                normalization_factor = 0.95 / max_ampl
                recorded_audio = recorded_audio * normalization_factor
                print(f"–ó–∞–ø–∏—Å—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–∞ —Å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–º {normalization_factor:.3f}")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø–∏—Å–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ
            performance_path = recording_dir / f"{Path(midi_path).stem}_performance.wav"
            sf.write(str(performance_path), recorded_audio, recorder.sample_rate)
            print(f"–ó–∞–ø–∏—Å—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {performance_path}")

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç—Ç–∞–ª–æ–Ω–Ω—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª
            reference_path = reference_dir / f"{Path(midi_path).stem}_reference.wav"
            generator = ReferenceGenerator(samples_dir="samples", sample_rate=recorder.sample_rate)
            
            if generator.generate_reference(midi_path, str(reference_path)):
                print(f"–≠—Ç–∞–ª–æ–Ω–Ω—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {reference_path}")
                
                # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ
                evaluator = PerformanceEvaluator(sr=recorder.sample_rate)
                results = evaluator.evaluate(str(reference_path), str(performance_path))
                
                message = ''
                print("\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–¶–ï–ù–ö–ò –ò–°–ü–û–õ–ù–ï–ù–ò–Ø ===")
                print(f"DTW —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {results['dtw_distance']:.2f}")
                message += f"DTW —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {results['dtw_distance']:.2f}\n"
                print(f"–û—Ü–µ–Ω–∫–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞: {results['similarity']:.3f} ({results['similarity']*100:.1f}%)")
                message += f"–û—Ü–µ–Ω–∫–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞: {results['similarity']:.3f} ({results['similarity']*100:.1f}%)\n"
                
                # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                if results['similarity'] >= 0.78:
                    print("–û—Ç–ª–∏—á–Ω–æ–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ! üéâ")
                    message += "–û—Ç–ª–∏—á–Ω–æ–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ! üéâ\n"
                elif results['similarity'] >= 0.7:
                    print("–•–æ—Ä–æ—à–µ–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ! üëç")
                    message += "–•–æ—Ä–æ—à–µ–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ! üëç\n"
                elif results['similarity'] >= 0.6:
                    print("–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ. –ï—Å—Ç—å –Ω–∞–¥ —á–µ–º –ø–æ—Ä–∞–±–æ—Ç–∞—Ç—å.")
                    message += "–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ. –ï—Å—Ç—å –Ω–∞–¥ —á–µ–º –ø–æ—Ä–∞–±–æ—Ç–∞—Ç—å.\n"
                else:
                    print("–ù—É–∂–Ω–æ –±–æ–ª—å—à–µ –ø—Ä–∞–∫—Ç–∏–∫–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑!")
                    message += "–ù—É–∂–Ω–æ –±–æ–ª—å—à–µ –ø—Ä–∞–∫—Ç–∏–∫–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑!\n"
                messagebox.showwarning("=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–¶–ï–ù–ö–ò –ò–°–ü–û–õ–ù–ï–ù–ò–Ø ===", message)
            else:
                print("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞")
                
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø–∏—Å–∏: {e}")
    else:
        print("–ó–∞–ø–∏—Å—å –∑–≤—É–∫–∞ –Ω–µ –±—ã–ª–∞ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∞ –∏–ª–∏ –ø—É—Å—Ç–∞")

if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    midi_file = "exercises/—ë–ª–æ—á–∫–∞.mid"  # –ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π –ø—É—Ç—å –∫ MIDI-—Ñ–∞–π–ª—É
    device_name = 'Realtek High Definition Audio (#1)'  # –ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –Ω—É–∂–Ω–æ–µ –∏–º—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    # –ï—Å–ª–∏ –∑–∞–¥–∞–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä device_name, —Ç–æ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∑–∞–ø–∏—Å—å –∑–≤—É–∫–∞ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å—Å—è –æ—Ü–µ–Ω–∫–∞ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
    run_visualization(midi_file, enable_sound=False, device_name=device_name)
